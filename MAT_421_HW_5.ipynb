{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ75OtxcDEIGwhUf5pdomf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/npnavas/MAT_421/blob/main/MAT_421_HW_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 Introduction\n",
        "Linear Algebra is one of the most useful fields in mathematics. It allows us to talk about mathematics through the use of vectorspaces and martirices. This naturally becomes a useful in applied fields like machine learning and data sciences as large amounts of data and information can be stored within matricies along with being able to use linear algebra to perform classifications of data for machine learning algorithms.  "
      ],
      "metadata": {
        "id": "cxYnMa01bu6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2 Elements of Linear Algebra\n",
        "Here we will talk about three of the pillars of linear algebra.\n",
        "## Vectors and Linear Independence\n",
        "Here we'll talk about some properties of vectors. Taking $\\mathbf{x_1},\\mathbf{x_1}\\in V$ where $V$ is a subspace of $\\mathbb{R}^n$ and $\\alpha,\\beta\\in \\mathbb{R}$ we can make a **linear combination** of vectors is some new vector $\\mathbf{y} = \\alpha\\mathbf{x_1}+\\beta\\mathbf{x_2}\\in V$, This allows us to create subspaces $X\\subseteq V$ along with a basis that spans this new subspace.\n",
        "We call a set of vectors $\\{\\mathbf{x_1},\\mathbf{x_2},\\cdots,\\mathbf{x_n}\\}$ linearaly independent if no vector in the set is a linear combination of the others in a set. \n",
        "## Orthogonality and Normality \n",
        "Othogonality of two vectors is defined as $(\\mathbf{x_i})^T\\cdot \\mathbf{x_j}=0.$. This operation is called an inner product. This is useful to show that a set of of vectors $X = \\{\\mathbf{x_1},\\mathbf{x_2},\\cdots,\\mathbf{x_n}\\}$ is linearly independent as if two vectors are linearly independent their inner product is 0. For a set of vectors to be linearly independent  \n",
        "$$\\forall \\mathbf{x_i},\\mathbf{x_j}\\in X,\\text{ s.t. } \\mathbf{x_i}\\neq\\mathbf{x_j}, (\\mathbf{x_i})^T\\mathbf{x_j}=0.$$\n",
        "\n",
        "Normality is defined as the following, a vector is normalized if $(\\mathbf{x_n})^T\\mathbf{x_n}=1$. This is useful when trying to construct a basis. It is preferable to use normalized bases in most cases so given a set of linearly independent set of vectors you can use both orthogonality and normality to generate a righthanded basis that those vectors span. This process is the Gram-Schmidt process. \n",
        "\n",
        "## Eigenvalues Eigenvectors \n",
        "Here the eigenvalue problem is given a matrix A we want to find scalars $\\lambda$ and vectors $\\mathbf{x}\\neq\\mathbf{0}$ such that $$A\\mathbf{x} = \\lambda\\mathbf{x}\\implies (A-\\lambda I)\\mathbf{x} = 0.$$\n",
        "These scalars and vectors that make this equation true are called eignevalues and eigenvectors.\n",
        "\n",
        "Here we can see that using numpy to see all these concepts in action"
      ],
      "metadata": {
        "id": "AxzGi6bXbt8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# basis vectors \n",
        "x1 = np.array([1/np.sqrt(2),1/np.sqrt(2),0])\n",
        "x2 = np.array([-1/np.sqrt(2),1/np.sqrt(2),0])\n",
        "x3 = np.array([0,0,1])\n",
        "\n",
        "# test for linear dependence \n",
        "print(\"Inner product of x1 and x2: \", x1.dot(x2))\n",
        "print(\"Inner product of x1 and x3: \", x1.dot(x3))\n",
        "print(\"Inner product of x2 and x3: \", x2.dot(x2))\n",
        "\n",
        "# test for normality \n",
        "print(\"Norm of x1\", x1.dot(x1)) #trucation error\n",
        "print(\"Norm of x2\", x2.dot(x2)) #trucation error\n",
        "print(\"Norm of x3\", x3.dot(x3))\n",
        "\n",
        "# find eigenvalues/vectors \n",
        "print('Eigenvalues: ',np.linalg.eig(np.transpose(np.array([x1,x2,x3])))[0])\n",
        "print('Eigenvectors: ',np.linalg.eig(np.transpose(np.array([x1,x2,x3])))[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp3JB2xpcniR",
        "outputId": "59065a28-fc0f-4d15-fbb1-d94a53efe4a2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inner product of x1 and x2:  0.0\n",
            "Inner product of x1 and x3:  0.0\n",
            "Inner product of x2 and x3:  0.9999999999999998\n",
            "Norm of x1 0.9999999999999998\n",
            "Norm of x2 0.9999999999999998\n",
            "Norm of x3 1\n",
            "Eigenvalues:  [0.70710678+0.70710678j 0.70710678-0.70710678j 1.        +0.j        ]\n",
            "Eigenvectors:  [[0.70710678+0.j         0.70710678-0.j         0.        +0.j        ]\n",
            " [0.        -0.70710678j 0.        +0.70710678j 0.        +0.j        ]\n",
            " [0.        +0.j         0.        -0.j         1.        +0.j        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.3 Linear Regression\n",
        "Linear regression is a method for solving models that depend linearly on their unknowns. First we'll look at $QR$ decomposition. $QR$ decomposision solves the linear least squares problem. How this works is given a system $A$ we can write it as a matrix and do the following decomposision $A = QR$, were $R$ is an upper triangular matrix. Here we'll use numpy's built-in `numpy.linalg.qr()` to do this decomposision for us."
      ],
      "metadata": {
        "id": "bpOcM7lscnzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "\n",
        "A = np.random.randn(3, 3)\n",
        "Q, R = np.linalg.qr(A)\n",
        "print(\"A:\\n\", A)\n",
        "print(\"Q:\\n\", Q)\n",
        "print(\"R:\\n\", R)\n",
        "# Confirmation that A = QR\n",
        "Q.dot(R)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI789XScxsCD",
        "outputId": "85e42619-e915-4b3d-e6b0-94199ca896f8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A:\n",
            " [[ 0.25566153 -0.66517822  1.24635485]\n",
            " [ 1.27761777 -2.09406083  1.14585776]\n",
            " [ 0.10640888 -0.13205306 -0.38731665]]\n",
            "Q:\n",
            " [[-0.19556686  0.96611428  0.16845415]\n",
            " [-0.97730658 -0.17773846 -0.11524274]\n",
            " [-0.08139688 -0.18716901  0.97894959]]\n",
            "R:\n",
            " [[-1.30728453  2.18737495 -1.33207366]\n",
            " [ 0.         -0.24572679  1.07295191]\n",
            " [ 0.          0.         -0.30126162]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.25566153, -0.66517822,  1.24635485],\n",
              "       [ 1.27761777, -2.09406083,  1.14585776],\n",
              "       [ 0.10640888, -0.13205306, -0.38731665]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note this does work for matricies that are not square"
      ],
      "metadata": {
        "id": "hYPLd9Rixmjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "randSize = np.random.randint(2,6)\n",
        "randSize2 = np.random.randint(2,6)\n",
        "print(randSize)\n",
        "print(randSize2)\n",
        "A = np.random.randn(randSize, randSize2)\n",
        "Q, R = np.linalg.qr(A)\n",
        "print(\"A:\\n\", A)\n",
        "print(\"Q:\\n\", Q)\n",
        "print(\"R:\\n\", R)\n",
        "# Confirmation that A = QR\n",
        "Q.dot(R)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3uS9GslcvQg",
        "outputId": "07590996-24e7-49bf-86c9-16cae57de243"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "5\n",
            "A:\n",
            " [[ 0.73141361  0.87870167 -1.13014427 -1.41524994  0.15520257]\n",
            " [ 0.80024739 -0.82697292 -0.79484102  0.2367814   0.7826815 ]\n",
            " [-0.69451319 -1.10140818  1.06504973  1.84179409  0.33348732]\n",
            " [ 0.20826461  0.25558343  0.30351146  0.55039521 -0.40619355]\n",
            " [ 1.57914012  2.93825805  0.61772033  0.17437812  1.02137358]]\n",
            "Q:\n",
            " [[-0.3571158  -0.03353323  0.58318282 -0.69633756 -0.21530357]\n",
            " [-0.39072418 -0.89756901 -0.15928444  0.12198744 -0.03810533]\n",
            " [ 0.33909901 -0.09670436 -0.62467568 -0.56738817 -0.40436504]\n",
            " [-0.10168608 -0.0069587  -0.2390948  -0.41704389  0.8709303 ]\n",
            " [-0.77102187  0.42877178 -0.43259708  0.06616737 -0.1736712 ]]\n",
            "R:\n",
            " [[-2.04811328 -2.65561684  0.56817453  0.84702558 -0.99434979]\n",
            " [ 0.          2.07737413  0.91107611 -0.27224088 -0.29920203]\n",
            " [ 0.          0.         -1.53757761 -2.22062112 -0.58720339]\n",
            " [ 0.          0.          0.         -0.24863695  0.03516932]\n",
            " [ 0.          0.          0.          0.         -0.72924006]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.73141361,  0.87870167, -1.13014427, -1.41524994,  0.15520257],\n",
              "       [ 0.80024739, -0.82697292, -0.79484102,  0.2367814 ,  0.7826815 ],\n",
              "       [-0.69451319, -1.10140818,  1.06504973,  1.84179409,  0.33348732],\n",
              "       [ 0.20826461,  0.25558343,  0.30351146,  0.55039521, -0.40619355],\n",
              "       [ 1.57914012,  2.93825805,  0.61772033,  0.17437812,  1.02137358]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ]
}